![img1](https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/teaser.gif)

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Teaser](https://img.shields.io/badge/Teaser_by-寝国-pink)](https://space.bilibili.com/177312952?spm_id_from=333.337.0.0)
<p align="left">
   ENGLISH | <a href="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/README_CN.md">简体中文</a>
</p>

# Awesome Animation Research 

This repository provides a curated collection of research for **🎞️hand-drawn animation / 🎞️cartoon videos**. 

💁‍♀️**What You'll Find Here:** **Anime Video Research.** Stuff closely related to hand-drawn animation(cartoon video) that could potentially **assist enthusiasts or professionals create animations**. e.g. Inbetweening, Colorization, etc.

🤷‍♀️**What's Not Included:** **General Anime Research.** i.e. Anime Style Transfer, Anime Image Enhancement, Anime Image generation. If you are interested in general anime research, please refer to this cool repo: [🕶️AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).

****

🙇‍♀️Creating animation is time-consuming and often involves arduour manual work. AI tools are changing this landscape. Researchers are coping with animation-specific challenges like inbetweening and frame-to-frame color propagation. 

Cartoon research is new, niche, interesting, and we look forward to more researchers, including you, contributing to it.

The repo will keep track of the latest research. Feel free to follow and star ! 🌟

## New Papers
<!-- [<span style="color:red">*new</span>]  -->

🚩【Generation】**ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.10881"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://lg-li.github.io/project/tooncomposer/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/TencentARC/ToonComposer"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/spaces/TencentARC/ToonComposer) &nbsp;\
*Lingen Li, Guangzhi Wang, Zhaoyang Zhang, Yaowei Li, Xiaoyu Li, Qi Dou, Jinwei Gu, Tianfan Xue, Ying Shan*\
[Aug., 2025] [arXiv 2025]

🚩【StoryBoard】**Story2Board: A Training-Free Approach for Expressive Storyboard Generation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.09983"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://daviddinkevich.github.io/Story2Board/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  
<a href="https://github.com/daviddinkevich/Story2Board"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*David Dinkevich, Matan Levy, Omri Avrahami, Dvir Samuel, Dani Lischinski*\
[Aug., 2025] [arXiv 2025]

🚩【StoryBoard】**Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.08949"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Ao Ma, Jiasong Feng, Ke Cao, Jing Wang, Yun Wang, Quanwei Zhang, Zhanjie Zhang*\
[Aug., 2025] [arXiv 2025]

🚩【3D】**CharacterShot: Controllable and Consistent 4D Character Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.07409"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/Jeoyal/CharacterShot"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Junyao Gao, Jiaxing Li, Wenran Liu, Yanhong Zeng, Fei Shen, Kai Chen, Yanan Sun, Cairong Zhao*\
[Aug., 2025] [arXiv 2025]



## Survey

**Generative AI for Cel-Animation: A Survey** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.06250"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yunlong10/Awesome-AI4Animation"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu*\
[Jan., 2025] [arXiv 2025]


## Datasets

**MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation** &nbsp; | &nbsp; 
<a href="https://www.arxiv.org/abs/2507.20368"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Shuolin Xu, Bingyuan Wang, Zeyu Cai, Fangteng Fu, Yue Ma, Tongyi Lee, Hongchuan Yu, Zeyu Wang*\
[Jul., 2025] [arXiv 2025]

**AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation** &nbsp; | &nbsp; 
<a href="https://www.arxiv.org/abs/2506.03126"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://qiulu66.github.io/animeshooter/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/qiulu66/Anime-Shooter"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://huggingface.co/datasets/qiulu66/AnimeShooter"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/qiulu66/AnimeShooterGen) &nbsp;\
*Lu Qiu, Yizhuo Li, Yuying Ge, Yixiao Ge, Ying Shan, Xihui Liu*\
[Jun., 2025] [arXiv 2025]

**LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2506.02733"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/datasets/LecterF/LinkTo-Anime) &nbsp;\
*Xiaoyi Feng, Kaifeng Zou, Caichun Cen, Tao Huang, Hui Guo, Zizhou Huang, Yingli Zhao, Mingqing Zhang, Diwei Wang, Yuntao Zou, Dagang Li*\
[Jun., 2025] [arXiv 2025]

**Anita Dataset: An Industrial Animation Dataset**  &nbsp; | &nbsp;
<a href="https://zhenglinpan.github.io/AnitaDataset_homepage/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/AnitaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1ctfD0sMpT2pVutJUOlyEYKhAxufMYmZ_/view?usp=sharing"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu* \
[26 Jun., 2024] [Github Repo, 2024]

**Sakuga-42M Dataset: Scaling Up Cartoon Research**  &nbsp; | &nbsp;
<a href="https://drive.google.com/file/d/1aeJqsBw92ebELEpP-oFBo-kcUpBzHm_E/view"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://zhenglinpan.github.io/Sakuga_42M/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/SakugaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://huggingface.co/datasets/aidenpan/Sakuga-42M"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu, Yuxuan Mu* \
[13 May., 2024] [arXiv, 2024]

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2211.05709"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href=""><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeRun"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [NeurIPS, 2022]


## Generative Methods

**ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.10881"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://lg-li.github.io/project/tooncomposer/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/TencentARC/ToonComposer"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/spaces/TencentARC/ToonComposer) &nbsp;\
*Lingen Li, Guangzhi Wang, Zhaoyang Zhang, Yaowei Li, Xiaoyu Li, Qi Dou, Jinwei Gu, Tianfan Xue, Ying Shan*\
[Aug., 2025] [arXiv 2025]

**LongAnimation: Long Animation Generation with Dynamic Global-Local Memory** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01945"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://cn-makers.github.io/long_animation_web/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/CN-makers/LongAnimation"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao*\
[Jul., 2025] [arXiv 2025]

**FairyGen: Storied Cartoon Video from a Single Child-Drawn Character** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2506.21272"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://jayleejia.github.io/FairyGen/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/GVCLab/FairyGen"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jiayi Zheng, Xiaodong Cun*\
[Jun., 2025] [arXiv 2025]

**DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2505.24733"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://kebii.github.io/DreamDance/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/Kebii/DreamDance"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jiaxu Zhang, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu, Guosheng Lin, Zhigang Tu*\
[May., 2025] [arXiv 2025]

**Aligning Anime Video Generation with Human Feedback** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2504.10044"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Bingwen Zhu, Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Yidi Wu, Huyang Sun, Zuxuan Wu*\
[Apr., 2025] [arXiv 2025]

**PhysAnimator: Physics-Guided Generative Cartoon Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.16550"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Xie, Yiwei Zhao, Ying Jiang, Chenfanfu Jiang*\
[Jan., 2025] [arXiv 2025]

**LayerAnimate: Layer-specific Control for Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.08295"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://layeranimate.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/IamCreateAI/LayerAnimate"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuxue Yang, Lue Fan, Zuzen Lin, Feng Wang, Zhaoxiang Zhang*\
[Jan., 2025] [arXiv 2025]

**AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.10255"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/bilibili/Index-anisora"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Qi Sen, Xingyu Zheng, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun*\
[Dec., 2024] [arXiv 2024]

**MikuDance: Animating Character Art with Mixed Motion Dynamics** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2411.08656"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://kebii.github.io/MikuDance/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Jiaxu Zhang, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu, Zhigang Tu*\
[Nov.,2024] [arXiv, 2024]


## StoryBoard

**Story2Board: A Training-Free Approach for Expressive Storyboard Generation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.09983"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://daviddinkevich.github.io/Story2Board/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  
<a href="https://github.com/daviddinkevich/Story2Board"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*David Dinkevich, Matan Levy, Omri Avrahami, Dvir Samuel, Dani Lischinski*\
[Aug., 2025] [arXiv 2025]

**Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.08949"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Ao Ma, Jiasong Feng, Ke Cao, Jing Wang, Yun Wang, Quanwei Zhang, Zhanjie Zhang*\
[Aug., 2025] [arXiv 2025]


## Colorization

**AnimeColor: Reference-based Animation Colorization with Diffusion Transformers** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.20158"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/IamCreateAI/AnimeColor"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Yuhong Zhang, Liyao Wang, Han Wang, Danni Wu, Zuzeng Lin, Feng Wang, Li Song*\
[Jul., 2025] [arXiv 2025]

**SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01586"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://bconstantine.github.io/SketchColour/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/bconstantine/SketchColour"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Bryan Constantine Sadihin, Michael Hua Wang, Shei Pern Chua, Hang Su*\
[Jul., 2025] [arXiv 2025]

**Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Liyao Wang; Zuzeng Lin; Danni Wu; Zihao Yu; Suzhe Zhang; Zixian Wu*\
[Mar., 2025] [ICASSP 2025]

**Image Referenced Sketch Colorization Based on Animation Creation Workflow** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2502.19937"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/tellurion-kanata/colorizeDiffusion"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Dingkun Yan, Xinrui Wang, Zhuoru Li, Suguru Saito, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo*\
[Feb., 2025] [arXiv 2025]

**AniDoc: Animation Creation Made Easier** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.14173"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yihao-meng/AniDoc"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://yihao-meng.github.io/AniDoc_demo/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yihao Meng, Hao Ouyang, Hanlin Wang, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Zhiheng Liu, Yujun Shen, Huamin Qu*\
[Dec., 2024] [arXiv 2024]

**Paint Bucket Colorization Using Anime Character Color Design Sheets** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2410.19424"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Yuekun Dai, Qinyue Li, Shangchen Zhou, Yihang Luo, Chongyi Li, Chen Change Loy*\
[Oct.,2024] [arXiv, 2024]

**LVCD: Reference-based Lineart Video Colorization with Diffusion Models**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.12960"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://luckyhzt.github.io/lvcd"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhitong Huang, Mohan Zhang, Jing Liao* \
[19 Sep. 2024] [arXiv, 2024]

**Continual few-shot patch-based learning for anime-style colorization**  &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s41095-024-0414-4"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Akinobu Maejima, Seitaro Shinagawa, Hiroyuki Kubo, Takuya Funatomi, Tatsuo Yotsukura, Satoshi Nakamura & Yasuhiro Mukaigawa* \
[09 Jul., 2024] [CVM, 2024]

**Learning Inclusion Matching for Animation Paint Bucket Colorization**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2403.18342"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://ykdai.github.io/projects/InclusionMatching"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=nNnPUItGvSo&ab_channel=YuekunDai"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuekun Dai, Shangchen Zhou, Qinyue Li, Chongyi Li, Chen Change Loy*\
[2024] [CVPR, 2024]

**Coloring anime line art videos with transformation region enhancement network** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] 

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2209.00185"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ribombee/SketchBetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Dagmar Lukka Loftsdóttir, Matthew Guzdial*\
[1 Sep., 2022] [ECCV, 2022] 

**Animation Line Art Colorization Based on Optical Flow Method** &nbsp; | &nbsp;
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] 

**The Animation Transformer: Visual Correspondence via Segment Matching** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2109.02614"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://cadmium.app/"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Evan Casey, Víctor Pérez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021]

**Artist-Guided Semiautomatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2006.13717"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2004.06718"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020]

**Deep Line Art Video Colorization with a Few References** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2003.10685"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020]

**Automatic Temporally Coherent Video Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/1904.09527"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Harry-Thasarathan/TCVC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi*



## Inbetweening & Interpolation

**Skeleton-Driven Inbetweening of Bitmap Character Drawings** &nbsp; | &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/inbetweening.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Kirill Brodt, Mikhail Bessmeltsev*\
[2024] [SIGGRAPH ASIA, 2024]

**Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening** &nbsp; | &nbsp; \
<a href="https://arxiv.org/abs/2308.13273"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/none-master/SAIN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1vyu_ePFN9sFjqxc-sPdSWuSCLnWFVUT7/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Jiaming Shen, Kun Hu, Wei Bao, Chang Wen Chen, Zhiyong Wang*\
[Aug., 2024] [ACMMM 2024]

**Thin-Plate Spline-based Interpolation for Animation Line Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2408.09131"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Tian-one/tps-inbetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Zhu, Wei Shang, Dongwei Ren, Wangmeng Zuo*\
[17 Aug., 2024] [arXiv, 2024]

**ToonCrafter: Generative Cartoon Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2405.17933"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://doubiiu.github.io/projects/ToonCrafter/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ToonCrafter/ToonCrafter"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jinbo Xing, Hanyuan Liu, Menghan Xia, Yong Zhang, Xintao Wang, Ying Shan, Tien-Tsin Wong*\
[29 May., 2024] [arxiv, 2024]

**Joint Stroke Tracing and Correspondence for 2D Animation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/3649890"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://markmohr.github.io/JoSTC/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/MarkMoHR/JoSTC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haoran Mo, Chengying Gao, Ruomei Wang*\
[9 Apr., 2024] [SIGGRAPH, 2024]

**Deep Geometrized Cartoon Line Inbetweening** &nbsp; | &nbsp;
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?si=9FViAZUyFdSfZzS5&v=iUF-LsqFKpI&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInbet"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1SNRGajIECxNwRp6ZJ0IlY7AEl2mRm2DR/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023]

**Exploring inbetween charts with trajectory-guided sliders for cutout animation** &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s11042-023-17354-x"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023]

**Enhanced Deep Animation Video Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2206.12657"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022]

**Improving the Perceptual Quality of 2D Animation Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2111.12792"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Shuhong Chen, Matthias Zwicker*\
[24 Nov., 2021] [arXiv, 2021] 

**Deep Animation Video Interpolation in the Wild** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2104.02495"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] 

**Deep Sketch-guided Cartoon Video Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2008.04149"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** &nbsp; | &nbsp;
<a href="https://ieeexplore.ieee.org/document/8803506"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019]

**DiLight: Digital light table – Inbetweening for 2D animations using guidelines** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017]




## Editing

**Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2401.03499"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024]

**Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/pdf/10.1145/3550454.3555439"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lllyasviel.github.io/GitPageToonDecompose/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Lvmin Zhang, Tien-Tsin Wong, Yuxin Liu*\
[Nov., 2022] [ACM 2022] 

**Toonsynth: example-based synthesis of hand-colored cartoon animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/3197517.3201326"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*M Dvorožnák, W Li, VG Kim, D Sýkora*\
[Jul., 2018] [TOG 2018]



## Tracking & Matching

**Globally Optimal Toon Tracking** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/2897824.2925872"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haichao Zhu, Xueting Liu, Tien-Tsin Wong, Pheng-Ann Heng* \
[11 Jul., 2016] [TOG, 2016]



## Segmentation

**Fast Leak-Resistant Segmentation for Anime Line Art** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/full/10.1145/3681758.3698003"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Benjamin Allen, Akinobu Maejima, Ken Anjyo*\
[Nov.,2024] [SIGGRAPH, 2024]

**Stereoscopizing Cel Animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/2508363.2508396"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xueting Liu, Xiangyu Mao, Xuan Yang, Linling Zhang, Tien-Tsin Wong* \
[11 Jul., 2016] [ACM, 2013]



## 3D&3DRotoscoping&3D Assistance

**CharacterShot: Controllable and Consistent 4D Character Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2508.07409"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/Jeoyal/CharacterShot"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Junyao Gao, Jiaxing Li, Wenran Liu, Yanhong Zeng, Fei Shen, Kai Chen, Yanan Sun, Cairong Zhao*\
[Aug., 2025] [arXiv 2025]


**Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation** &nbsp; | &nbsp; 
<a href="https://www.arxiv.org/abs/2504.19189"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://zhongleilz.github.io/Sketch2Anim/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://www.youtube.com/watch?v=5xZacNOLMKM"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Lei Zhong, Chuan Guo, Yiming Xie, Jiawei Wang, Changjian Li*\
[Apr., 2025] [arXiv 2025]

**StdGEN: Semantic-Decomposed 3D Character Generation from Single Images** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2411.05738"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://stdgen.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/hyz317/StdGEN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Yuze He, Yanning Zhou, Wang Zhao, Zhongkai Wu, Kaiwen Xiao, Wei Yang, Yong-Jin Liu, Xiao Han*\
[Mar., 2025] [CVPR 2025]

**DrawingSpinUp: 3D Animation from Single Character Drawings** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.08615"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lordliang.github.io/DrawingSpinUp/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/LordLiang/DrawingSpinUp"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
[🤗](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Jie Zhou, Chufeng Xiao, Miu-Ling Lam, Hongbo Fu* \
[13 Sep. 2024] [arXiv, 2024]

**Toon3D: Seeing Cartoons from a New Perspective** &nbsp; | &nbsp;
<a href="https://www.arxiv.org/abs/2405.10320"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://toon3d.studio/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=tJ7UKALsF-0&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ethanweber/toon3d"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
[🤗](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Ethan Weber, Riley Peterlinz, Rohan Mathur, Frederik Warburg, Alexei A. Efros, Angjoo Kanazawa* \
[2024] [Arxiv, 2024]







## How to Contribute
We encourage animation enthusiasts, researchers, and scholars to contribute to this repository by adding relevant papers, articles, and resources. Your contributions will help build a valuable reference for anyone interested in the art and science of animation.

To contribute, simply fork this repository, make your additions or improvements, and submit a pull request. Please follow the contribution guidelines outlined in the repository's README file.

---

<div align="center">
    <em>May Animation Get Better With Us.</em>
</div>

<div align="center">
   <img src="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/Hatsune_Miku_@illufinch.png" width="40" >
</div>
<p align="center"><sub><i>icon by Twitter</i>©illufinch</sub></p>
