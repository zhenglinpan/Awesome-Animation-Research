![img1](https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/teaser.gif)

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Teaser](https://img.shields.io/badge/Teaser_by-å¯å›½-pink)](https://space.bilibili.com/177312952?spm_id_from=333.337.0.0)
<p align="left">
   <a href="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/README.md">ENGLISH</a> | ç®€ä½“ä¸­æ–‡
</p>

# Awesome Animation Research ğŸ¥ğŸ“š

æœ¬repoæ”¶é›†äº†ä¸€æ‰¹å…³äº**ğŸï¸èµ›ç’çåŠ¨ç”»/ğŸï¸å¡é€šåŠ¨ç”»**çš„å„ç§ç ”ç©¶ã€æ•°æ®é›†åŠå…¶ç›¸å…³èµ„æºã€‚

ğŸ’â€â™€ï¸**åœ¨è¿™é‡Œä½ å¯ä»¥æ‰¾åˆ°:** æœ‰å¯èƒ½å¸®åŠ©åˆ°åŠ¨ç”»ä¸šç•Œçš„æŠ€æœ¯è®ºæ–‡ã€æ•°æ®é›†ã€repoç­‰ã€‚ä¾‹å¦‚ï¼šä¸­å‰²ç”Ÿæˆã€åŸç”»ä¸Šè‰²ç­‰ã€‚

ğŸ¤·â€â™€ï¸**è¿™ä¸ªrepoä¸åŒ…æ‹¬:** å¹¿ä¹‰çš„Animeç ”ç©¶ã€‚ä¾‹å¦‚ï¼šåŠ¨æ¼«é£æ ¼æ»¤é•œã€åŠ¨æ¼«å›¾åƒè¶…åˆ†ã€åŠ¨æ¼«äººç‰©ç”Ÿæˆç­‰ã€‚å¦‚æœä½ å¯¹å¹¿ä¹‰çš„Animeç ”ç©¶æ„Ÿå…´è¶£ï¼Œè¯·ç§»æ­¥[AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).


****

ğŸ™‡â€â™€ï¸èµ›ç’çåŠ¨ç”»åˆ¶ä½œéå¸¸ä¸æ˜“ã€éœ€è¦å¤§é‡åŠ¨ç”»äººä¸€å¸§å¸§åœ°æ‰‹ç»˜ï¼Œè¿™ä¼šèŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚è®¡ç®—æœºè§†è§‰æŠ€æœ¯ä¹Ÿè®¸æ­£åœ¨æ”¹å˜è¿™ä¸€ç°çŠ¶ï¼Œæœ‰ä¸å°‘çš„ç ”ç©¶è€…æ­£åœ¨å°è¯•åˆ©ç”¨è¿™ä¸€æŠ€æœ¯è¾…åŠ©åŠ¨ç”»åˆ¶ä½œä¸­çš„æŸäº›ç¯èŠ‚ï¼Œä¾‹å¦‚è‡ªåŠ¨ä¸­å‰²ã€è‡ªåŠ¨ä¸Šè‰²ç­‰ã€‚

ç›®å‰è¿™ä¸ªrepoåˆ—è¡¨ç›®å‰è¿˜å¾ˆçŸ­ï¼Œå› ä¸ºåŠ¨ç”»çš„è®¡ç®—æœºè§†è§‰ç ”ç©¶æ˜¯ä¸€ä¸ªç›¸å¯¹æ–°å…´ä¸”å°ä¼—çš„é¢†åŸŸï¼Œæˆ‘ä»¬æœŸå¾…æ›´å¤šçš„ç ”ç©¶è€…ï¼ˆä¹ŸåŒ…æ‹¬ä½ ï¼‰ä¸€èµ·ä¸ºè¿™ä¸ªé¢†åŸŸçš„å‘å±•åšå‡ºè´¡çŒ®ã€‚

æœ¬repoä¼šæŒç»­å…³æ³¨æœ€æ–°çš„ç ”ç©¶æˆæœï¼Œæ¬¢è¿å…³æ³¨! ğŸŒŸ

## æ–°æ–‡ç« 
<!-- [<span style="color:red">*new</span>]  -->

ğŸš©ã€3Dã€‘ **StdGEN: Semantic-Decomposed 3D Character Generation from Single Images** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://stdgen.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/hyz317/StdGEN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[ğŸ¤—](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Yuze He, Yanning Zhou, Wang Zhao, Zhongkai Wu, Kaiwen Xiao, Wei Yang, Yong-Jin Liu, Xiao Han*\
[Mar., 2025] [CVPR 2025]

ğŸš©ã€ä¸Šè‰²ã€‘ **Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Liyao Wang; Zuzeng Lin; Danni Wu; Zihao Yu; Suzhe Zhang; Zixian Wu*\
[Mar., 2025] [ICASSP 2025]

ğŸš©ã€ä¸Šè‰²ã€‘ **Image Referenced Sketch Colorization Based on Animation Creation Workflow** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2502.19937"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/tellurion-kanata/colorizeDiffusion"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Dingkun Yan, Xinrui Wang, Zhuoru Li, Suguru Saito, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo*\
[Feb., 2025] [arXiv 2025]







## ç»¼è¿°

**Generative AI for Cel-Animation: A Survey** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.06250"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yunlong10/Awesome-AI4Animation"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu*\
[Jan., 2025] [arXiv 2025]


## æ•°æ®é›†

**Anita Dataset: An Industrial Animation Dataset**  &nbsp; | &nbsp;
<a href="https://zhenglinpan.github.io/AnitaDataset_homepage/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/AnitaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1ctfD0sMpT2pVutJUOlyEYKhAxufMYmZ_/view?usp=sharing"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu* \
[26 Jun., 2024] [Github Repo, 2024]

**Sakuga-42M Dataset: Scaling Up Cartoon Research**  &nbsp; | &nbsp;
<a href="https://drive.google.com/file/d/1aeJqsBw92ebELEpP-oFBo-kcUpBzHm_E/view"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://zhenglinpan.github.io/Sakuga_42M/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/SakugaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://huggingface.co/datasets/aidenpan/Sakuga-42M"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu, Yuxuan Mu* \
[13 May., 2024] [arXiv, 2024]

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2211.05709"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href=""><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeRun"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [NeurIPS, 2022]


## ç”Ÿæˆ

**PhysAnimator: Physics-Guided Generative Cartoon Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.16550"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Xie, Yiwei Zhao, Ying Jiang, Chenfanfu Jiang*\
[Jan., 2025] [arXiv 2025]

**LayerAnimate: Layer-specific Control for Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.08295"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://layeranimate.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/IamCreateAI/LayerAnimate"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuxue Yang, Lue Fan, Zuzen Lin, Feng Wang, Zhaoxiang Zhang*\
[Jan., 2025] [arXiv 2025]

**AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.10255"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/bilibili/Index-anisora"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Qi Sen, Xingyu Zheng, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun*\
[Dec., 2024] [arXiv 2024]

**MikuDance: Animating Character Art with Mixed Motion Dynamics** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2411.08656"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://kebii.github.io/MikuDance/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Jiaxu Zhang, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu, Zhigang Tu*\
[Nov.,2024] [arXiv, 2024]


## ä¸Šè‰²

**Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Liyao Wang; Zuzeng Lin; Danni Wu; Zihao Yu; Suzhe Zhang; Zixian Wu*\
[Mar., 2025] [ICASSP 2025]

**Image Referenced Sketch Colorization Based on Animation Creation Workflow** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2502.19937"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/tellurion-kanata/colorizeDiffusion"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Dingkun Yan, Xinrui Wang, Zhuoru Li, Suguru Saito, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo*\
[Feb., 2025] [arXiv 2025]

**AniDoc: Animation Creation Made Easier** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.14173"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yihao-meng/AniDoc"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://yihao-meng.github.io/AniDoc_demo/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yihao Meng, Hao Ouyang, Hanlin Wang, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Zhiheng Liu, Yujun Shen, Huamin Qu*\
[Dec., 2024] [arXiv 2024]

**Paint Bucket Colorization Using Anime Character Color Design Sheets** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2410.19424"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Yuekun Dai, Qinyue Li, Shangchen Zhou, Yihang Luo, Chongyi Li, Chen Change Loy*\
[Oct.,2024] [arXiv, 2024]

**LVCD: Reference-based Lineart Video Colorization with Diffusion Models**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.12960"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://luckyhzt.github.io/lvcd"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhitong Huang, Mohan Zhang, Jing Liao* \
[19 Sep. 2024] [arXiv, 2024]

**Continual few-shot patch-based learning for anime-style colorization**  &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s41095-024-0414-4"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Akinobu Maejima, Seitaro Shinagawa, Hiroyuki Kubo, Takuya Funatomi, Tatsuo Yotsukura, Satoshi Nakamura & Yasuhiro Mukaigawa* \
[09 Jul., 2024] [CVM, 2024]

**Learning Inclusion Matching for Animation Paint Bucket Colorization**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2403.18342"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://ykdai.github.io/projects/InclusionMatching"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=nNnPUItGvSo&ab_channel=YuekunDai"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuekun Dai, Shangchen Zhou, Qinyue Li, Chongyi Li, Chen Change Loy*\
[2024] [CVPR, 2024]

**Coloring anime line art videos with transformation region enhancement network** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] 

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2209.00185"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ribombee/SketchBetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Dagmar Lukka LoftsdÃ³ttir, Matthew Guzdial*\
[1 Sep., 2022] [ECCV, 2022] 

**Animation Line Art Colorization Based on Optical Flow Method** &nbsp; | &nbsp;
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] 

**The Animation Transformer: Visual Correspondence via Segment Matching** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2109.02614"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://cadmium.app/"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Evan Casey, VÃ­ctor PÃ©rez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021]

**Artist-Guided Semiautomatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2006.13717"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2004.06718"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020]

**Deep Line Art Video Colorization with a Few References** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2003.10685"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020]

**Automatic Temporally Coherent Video Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/1904.09527"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Harry-Thasarathan/TCVC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi*





## ä¸­å‰²/è¡¥å¸§

**Skeleton-Driven Inbetweening of Bitmap Character Drawings** &nbsp; | &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/inbetweening.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Kirill Brodt, Mikhail Bessmeltsev*\
[2024] [SIGGRAPH ASIA, 2024]

**Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening** &nbsp; | &nbsp; \
<a href="https://arxiv.org/abs/2308.13273"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/none-master/SAIN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1vyu_ePFN9sFjqxc-sPdSWuSCLnWFVUT7/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Jiaming Shen, Kun Hu, Wei Bao, Chang Wen Chen, Zhiyong Wang*\
[Aug., 2024] [ACMMM 2024]

**Thin-Plate Spline-based Interpolation for Animation Line Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2408.09131"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Tian-one/tps-inbetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Zhu, Wei Shang, Dongwei Ren, Wangmeng Zuo*\
[17 Aug., 2024] [arXiv, 2024]

**ToonCrafter: Generative Cartoon Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2405.17933"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://doubiiu.github.io/projects/ToonCrafter/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ToonCrafter/ToonCrafter"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jinbo Xing, Hanyuan Liu, Menghan Xia, Yong Zhang, Xintao Wang, Ying Shan, Tien-Tsin Wong*\
[29 May., 2024] [arxiv, 2024]

**Joint Stroke Tracing and Correspondence for 2D Animation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/3649890"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://markmohr.github.io/JoSTC/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/MarkMoHR/JoSTC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haoran Mo, Chengying Gao, Ruomei Wang*\
[9 Apr., 2024] [SIGGRAPH, 2024]

**Deep Geometrized Cartoon Line Inbetweening** &nbsp; | &nbsp;
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?si=9FViAZUyFdSfZzS5&v=iUF-LsqFKpI&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInbet"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1SNRGajIECxNwRp6ZJ0IlY7AEl2mRm2DR/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023]

**Exploring inbetween charts with trajectory-guided sliders for cutout animation** &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s11042-023-17354-x"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023]

**Enhanced Deep Animation Video Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2206.12657"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022]

**Improving the Perceptual Quality of 2D Animation Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2111.12792"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Shuhong Chen, Matthias Zwicker*\
[24 Nov., 2021] [arXiv, 2021] 

**Deep Animation Video Interpolation in the Wild** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2104.02495"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] 

**Deep Sketch-guided Cartoon Video Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2008.04149"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** &nbsp; | &nbsp;
<a href="https://ieeexplore.ieee.org/document/8803506"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019]

**DiLight: Digital light table â€“ Inbetweening for 2D animations using guidelines** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017]



## ç¼–è¾‘

**Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2401.03499"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024]

**Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/pdf/10.1145/3550454.3555439"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lllyasviel.github.io/GitPageToonDecompose/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Lvmin Zhang, Tien-Tsin Wong, Yuxin Liu*\
[Nov., 2022] [ACM 2022] 

**Toonsynth: example-based synthesis of hand-colored cartoon animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/3197517.3201326"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*M DvoroÅ¾nÃ¡k, W Li, VG Kim, D SÃ½kora*\
[Jul., 2018] [TOG 2018]

## è·Ÿè¸ª/åŒ¹é…

**Globally Optimal Toon Tracking** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/2897824.2925872"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haichao Zhu, Xueting Liu, Tien-Tsin Wong, Pheng-Ann Heng* \
[11 Jul., 2016] [TOG, 2016]


## åˆ†å‰²

**Fast Leak-Resistant Segmentation for Anime Line Art** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/full/10.1145/3681758.3698003"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Benjamin Allen, Akinobu Maejima, Ken Anjyo*\
[Nov.,2024] [SIGGRAPH, 2024]

**Stereoscopizing Cel Animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/2508363.2508396"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xueting Liu, Xiangyu Mao, Xuan Yang, Linling Zhang, Tien-Tsin Wong* \
[11 Jul., 2016] [ACM, 2013]

## 3D/è½¬æ/3Dè¾…åŠ©

**StdGEN: Semantic-Decomposed 3D Character Generation from Single Images** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://stdgen.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/hyz317/StdGEN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[ğŸ¤—](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Yuze He, Yanning Zhou, Wang Zhao, Zhongkai Wu, Kaiwen Xiao, Wei Yang, Yong-Jin Liu, Xiao Han*\
[Mar., 2025] [CVPR 2025]

**DrawingSpinUp: 3D Animation from Single Character Drawings** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.08615"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lordliang.github.io/DrawingSpinUp/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/LordLiang/DrawingSpinUp"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jie Zhou, Chufeng Xiao, Miu-Ling Lam, Hongbo Fu* \
[13 Sep. 2024] [arXiv, 2024]

**Toon3D: Seeing Cartoons from a New Perspective** &nbsp; | &nbsp;
<a href="https://www.arxiv.org/abs/2405.10320"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://toon3d.studio/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=tJ7UKALsF-0&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ethanweber/toon3d"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
[ğŸ¤—](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Ethan Weber, Riley Peterlinz, Rohan Mathur, Frederik Warburg, Alexei A. Efros, Angjoo Kanazawa* \
[2024] [Arxiv, 2024]



## å¦‚ä½•Contribute 
æˆ‘ä»¬é¼“åŠ±åŠ¨ç”»çˆ±å¥½è€…ã€ç ”ç©¶è€…é€šè¿‡æ·»åŠ ç›¸å…³è®ºæ–‡ã€æ–‡ç« å’Œå„ç±»èµ„æºçš„å½¢å¼ä¸ºæœ¬èµ„æ–™åº“åšå‡ºè´¡çŒ®ã€‚æ‚¨çš„è´¡çŒ®å°†æœ‰åŠ©äºä¸ºä»»ä½•å¯¹åŠ¨ç”»ç ”ç©¶æ„Ÿå…´è¶£çš„äººæä¾›æœ‰ä»·å€¼çš„å‚è€ƒã€‚

åªéœ€ fork æœ¬èµ„æºåº“ï¼Œè¿›è¡Œæ·»åŠ æˆ–æ”¹è¿›ï¼Œå¹¶pull requestå³å¯ã€‚

---

<div align="center">
    <em>å¸Œæœ›åŠ¨ç”»å› æˆ‘ä»¬è€Œæ›´å¥½.</em>
</div>

<div align="center">
   <img src="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/Hatsune_Miku_@illufinch.png" width="40" >
</div>
<p align="center"><sub><i>å›¾æ ‡ by Twitter</i>Â©illufinch</sub></p>
