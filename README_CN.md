![img1](https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/teaser.gif)

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Teaser](https://img.shields.io/badge/Teaser_by-寝国-pink)](https://space.bilibili.com/177312952?spm_id_from=333.337.0.0)
<p align="left">
   <a href="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/README.md">ENGLISH</a> | 简体中文
</p>

# Awesome Animation Research 🎥📚

本repo收集了一批关于**🎞️赛璐珞动画/🎞️卡通动画**的各种研究、数据集及其相关资源。

💁‍♀️**在这里你可以找到:** 有可能帮助到动画业界的技术论文、数据集、repo等。例如：中割生成、原画上色等。

🤷‍♀️**这个repo不包括:** 广义的Anime研究。例如：动漫风格滤镜、动漫图像超分、动漫人物生成等。如果你对广义的Anime研究感兴趣，请移步[AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).


****

🙇‍♀️赛璐珞动画制作非常不易、需要大量动画人一帧帧地手绘，这会花费大量的时间和精力。计算机视觉技术也许正在改变这一现状，有不少的研究者正在尝试利用这一技术辅助动画制作中的某些环节，例如自动中割、自动上色等。

目前这个repo列表目前还很短，因为动画的计算机视觉研究是一个相对新兴且小众的领域，我们期待更多的研究者（也包括你）一起为这个领域的发展做出贡献。

本repo会持续关注最新的研究成果，欢迎关注! 🌟

## 新文章
<!-- [<span style="color:red">*new</span>]  -->


🚩【上色】**AnimeColor: Reference-based Animation Colorization with Diffusion Transformers** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.20158"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/IamCreateAI/AnimeColor"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
*Yuhong Zhang, Liyao Wang, Han Wang, Danni Wu, Zuzeng Lin, Feng Wang, Li Song*\
[Jul., 2025] [arXiv 2025]

🚩【上色】**SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01586"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://bconstantine.github.io/SketchColour/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/bconstantine/SketchColour"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Bryan Constantine Sadihin, Michael Hua Wang, Shei Pern Chua, Hang Su*\
[Jul., 2025] [arXiv 2025]

🚩【生成】**LongAnimation: Long Animation Generation with Dynamic Global-Local Memory** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01945"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://cn-makers.github.io/long_animation_web/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/CN-makers/LongAnimation"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao*\
[Jul., 2025] [arXiv 2025]

🚩【数据集】**MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation** &nbsp; | &nbsp; 
<a href="https://www.arxiv.org/abs/2507.20368"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Shuolin Xu, Bingyuan Wang, Zeyu Cai, Fangteng Fu, Yue Ma, Tongyi Lee, Hongchuan Yu, Zeyu Wang*\
[Jul., 2025] [arXiv 2025]

🚩【生成】**FairyGen: Storied Cartoon Video from a Single Child-Drawn Character** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2506.21272"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://jayleejia.github.io/FairyGen/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/GVCLab/FairyGen"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jiayi Zheng, Xiaodong Cun*\
[Jun., 2025] [arXiv 2025]






## 综述

**Generative AI for Cel-Animation: A Survey** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.06250"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yunlong10/Awesome-AI4Animation"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yunlong Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu*\
[Jan., 2025] [arXiv 2025]


## 数据集

**MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation** &nbsp; | &nbsp; 
<a href="https://www.arxiv.org/abs/2507.20368"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Shuolin Xu, Bingyuan Wang, Zeyu Cai, Fangteng Fu, Yue Ma, Tongyi Lee, Hongchuan Yu, Zeyu Wang*\
[Jul., 2025] [arXiv 2025]

**Anita Dataset: An Industrial Animation Dataset**  &nbsp; | &nbsp;
<a href="https://zhenglinpan.github.io/AnitaDataset_homepage/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/AnitaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1ctfD0sMpT2pVutJUOlyEYKhAxufMYmZ_/view?usp=sharing"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu* \
[26 Jun., 2024] [Github Repo, 2024]

**Sakuga-42M Dataset: Scaling Up Cartoon Research**  &nbsp; | &nbsp;
<a href="https://drive.google.com/file/d/1aeJqsBw92ebELEpP-oFBo-kcUpBzHm_E/view"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://zhenglinpan.github.io/Sakuga_42M/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/zhenglinpan/SakugaDataset"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://huggingface.co/datasets/aidenpan/Sakuga-42M"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhenglin Pan, Yu Zhu, Yuxuan Mu* \
[13 May., 2024] [arXiv, 2024]

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2211.05709"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href=""><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeRun"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lisiyao21.github.io/projects/AnimeRun"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [NeurIPS, 2022]


## 生成

**LongAnimation: Long Animation Generation with Dynamic Global-Local Memory** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01945"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://cn-makers.github.io/long_animation_web/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/CN-makers/LongAnimation"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao*\
[Jul., 2025] [arXiv 2025]

**FairyGen: Storied Cartoon Video from a Single Child-Drawn Character** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2506.21272"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://jayleejia.github.io/FairyGen/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/GVCLab/FairyGen"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jiayi Zheng, Xiaodong Cun*\
[Jun., 2025] [arXiv 2025]

**Aligning Anime Video Generation with Human Feedback** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2504.10044"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Bingwen Zhu, Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Yidi Wu, Huyang Sun, Zuxuan Wu*\
[Apr., 2025] [arXiv 2025]

**PhysAnimator: Physics-Guided Generative Cartoon Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.16550"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Xie, Yiwei Zhao, Ying Jiang, Chenfanfu Jiang*\
[Jan., 2025] [arXiv 2025]

**LayerAnimate: Layer-specific Control for Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2501.08295"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://layeranimate.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/IamCreateAI/LayerAnimate"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuxue Yang, Lue Fan, Zuzen Lin, Feng Wang, Zhaoxiang Zhang*\
[Jan., 2025] [arXiv 2025]

**AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.10255"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/bilibili/Index-anisora"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Qi Sen, Xingyu Zheng, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun*\
[Dec., 2024] [arXiv 2024]

**MikuDance: Animating Character Art with Mixed Motion Dynamics** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2411.08656"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://kebii.github.io/MikuDance/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Jiaxu Zhang, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu, Zhigang Tu*\
[Nov.,2024] [arXiv, 2024]


## 上色

**AnimeColor: Reference-based Animation Colorization with Diffusion Transformers** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.20158"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/IamCreateAI/AnimeColor"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
*Yuhong Zhang, Liyao Wang, Han Wang, Danni Wu, Zuzeng Lin, Feng Wang, Li Song*\
[Jul., 2025] [arXiv 2025]

**SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2507.01586"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://bconstantine.github.io/SketchColour/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/bconstantine/SketchColour"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Bryan Constantine Sadihin, Michael Hua Wang, Shei Pern Chua, Hang Su*\
[Jul., 2025] [arXiv 2025]

**Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching** &nbsp; | &nbsp; 
<a href="https://ieeexplore.ieee.org/abstract/document/10888082"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Liyao Wang; Zuzeng Lin; Danni Wu; Zihao Yu; Suzhe Zhang; Zixian Wu*\
[Mar., 2025] [ICASSP 2025]

**Image Referenced Sketch Colorization Based on Animation Creation Workflow** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2502.19937"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/tellurion-kanata/colorizeDiffusion"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Dingkun Yan, Xinrui Wang, Zhuoru Li, Suguru Saito, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo*\
[Feb., 2025] [arXiv 2025]

**AniDoc: Animation Creation Made Easier** &nbsp; | &nbsp; 
<a href="https://arxiv.org/pdf/2412.14173"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/yihao-meng/AniDoc"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://yihao-meng.github.io/AniDoc_demo/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yihao Meng, Hao Ouyang, Hanlin Wang, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Zhiheng Liu, Yujun Shen, Huamin Qu*\
[Dec., 2024] [arXiv 2024]

**Paint Bucket Colorization Using Anime Character Color Design Sheets** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2410.19424"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Yuekun Dai, Qinyue Li, Shangchen Zhou, Yihang Luo, Chongyi Li, Chen Change Loy*\
[Oct.,2024] [arXiv, 2024]

**LVCD: Reference-based Lineart Video Colorization with Diffusion Models**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.12960"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://luckyhzt.github.io/lvcd"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Zhitong Huang, Mohan Zhang, Jing Liao* \
[19 Sep. 2024] [arXiv, 2024]

**Continual few-shot patch-based learning for anime-style colorization**  &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s41095-024-0414-4"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Akinobu Maejima, Seitaro Shinagawa, Hiroyuki Kubo, Takuya Funatomi, Tatsuo Yotsukura, Satoshi Nakamura & Yasuhiro Mukaigawa* \
[09 Jul., 2024] [CVM, 2024]

**Learning Inclusion Matching for Animation Paint Bucket Colorization**  &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2403.18342"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://ykdai.github.io/projects/InclusionMatching"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=nNnPUItGvSo&ab_channel=YuekunDai"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ykdai/BasicPBC/tree/main/dataset"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yuekun Dai, Shangchen Zhou, Qinyue Li, Chongyi Li, Chen Change Loy*\
[2024] [CVPR, 2024]

**Coloring anime line art videos with transformation region enhancement network** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] 

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2209.00185"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ribombee/SketchBetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Dagmar Lukka Loftsdóttir, Matthew Guzdial*\
[1 Sep., 2022] [ECCV, 2022] 

**Animation Line Art Colorization Based on Optical Flow Method** &nbsp; | &nbsp;
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] 

**The Animation Transformer: Visual Correspondence via Segment Matching** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2109.02614"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://cadmium.app/"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Evan Casey, Víctor Pérez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021]

**Artist-Guided Semiautomatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2006.13717"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2004.06718"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020]

**Deep Line Art Video Colorization with a Few References** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2003.10685"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020]

**Automatic Temporally Coherent Video Colorization** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/1904.09527"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Harry-Thasarathan/TCVC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi*





## 中割/补帧

**Skeleton-Driven Inbetweening of Bitmap Character Drawings** &nbsp; | &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/inbetweening.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www-labs.iro.umontreal.ca/~bmpix/inbetweening/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Kirill Brodt, Mikhail Bessmeltsev*\
[2024] [SIGGRAPH ASIA, 2024]

**Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening** &nbsp; | &nbsp; \
<a href="https://arxiv.org/abs/2308.13273"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/none-master/SAIN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1vyu_ePFN9sFjqxc-sPdSWuSCLnWFVUT7/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Jiaming Shen, Kun Hu, Wei Bao, Chang Wen Chen, Zhiyong Wang*\
[Aug., 2024] [ACMMM 2024]

**Thin-Plate Spline-based Interpolation for Animation Line Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2408.09131"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/Tian-one/tps-inbetween"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Tianyi Zhu, Wei Shang, Dongwei Ren, Wangmeng Zuo*\
[17 Aug., 2024] [arXiv, 2024]

**ToonCrafter: Generative Cartoon Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2405.17933"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://doubiiu.github.io/projects/ToonCrafter/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ToonCrafter/ToonCrafter"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jinbo Xing, Hanyuan Liu, Menghan Xia, Yong Zhang, Xintao Wang, Ying Shan, Tien-Tsin Wong*\
[29 May., 2024] [arxiv, 2024]

**Joint Stroke Tracing and Correspondence for 2D Animation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/3649890"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://markmohr.github.io/JoSTC/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/MarkMoHR/JoSTC"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haoran Mo, Chengying Gao, Ruomei Wang*\
[9 Apr., 2024] [SIGGRAPH, 2024]

**Deep Geometrized Cartoon Line Inbetweening** &nbsp; | &nbsp;
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?si=9FViAZUyFdSfZzS5&v=iUF-LsqFKpI&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInbet"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://drive.google.com/file/d/1SNRGajIECxNwRp6ZJ0IlY7AEl2mRm2DR/view"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023]

**Exploring inbetween charts with trajectory-guided sliders for cutout animation** &nbsp; | &nbsp;
<a href="https://link.springer.com/article/10.1007/s11042-023-17354-x"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023]

**Enhanced Deep Animation Video Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2206.12657"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022]

**Improving the Perceptual Quality of 2D Animation Interpolation** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2111.12792"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Shuhong Chen, Matthias Zwicker*\
[24 Nov., 2021] [arXiv, 2021] 

**Deep Animation Video Interpolation in the Wild** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2104.02495"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/lisiyao21/AnimeInterp/"><img src="./assets/dataset.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] 

**Deep Sketch-guided Cartoon Video Inbetweening** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2008.04149"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** &nbsp; | &nbsp;
<a href="https://ieeexplore.ieee.org/document/8803506"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019]

**DiLight: Digital light table – Inbetweening for 2D animations using guidelines** &nbsp; | &nbsp;
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017]



## 编辑

**Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2401.03499"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024]

**Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/pdf/10.1145/3550454.3555439"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lllyasviel.github.io/GitPageToonDecompose/"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Lvmin Zhang, Tien-Tsin Wong, Yuxin Liu*\
[Nov., 2022] [ACM 2022] 

**Toonsynth: example-based synthesis of hand-colored cartoon animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/3197517.3201326"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*M Dvorožnák, W Li, VG Kim, D Sýkora*\
[Jul., 2018] [TOG 2018]

## 跟踪/匹配

**Globally Optimal Toon Tracking** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/10.1145/2897824.2925872"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Haichao Zhu, Xueting Liu, Tien-Tsin Wong, Pheng-Ann Heng* \
[11 Jul., 2016] [TOG, 2016]


## 分割

**Fast Leak-Resistant Segmentation for Anime Line Art** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/full/10.1145/3681758.3698003"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;  \
*Benjamin Allen, Akinobu Maejima, Ken Anjyo*\
[Nov.,2024] [SIGGRAPH, 2024]

**Stereoscopizing Cel Animations** &nbsp; | &nbsp;
<a href="https://dl.acm.org/doi/abs/10.1145/2508363.2508396"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;\
*Xueting Liu, Xiangyu Mao, Xuan Yang, Linling Zhang, Tien-Tsin Wong* \
[11 Jul., 2016] [ACM, 2013]

## 3D/转描/3D辅助

**StdGEN: Semantic-Decomposed 3D Character Generation from Single Images** &nbsp; | &nbsp; 
<a href="https://arxiv.org/abs/2411.05738"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://stdgen.github.io/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
<a href="https://github.com/hyz317/StdGEN"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; 
[🤗](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Yuze He, Yanning Zhou, Wang Zhao, Zhongkai Wu, Kaiwen Xiao, Wei Yang, Yong-Jin Liu, Xiao Han*\
[Mar., 2025] [CVPR 2025]

**DrawingSpinUp: 3D Animation from Single Character Drawings** &nbsp; | &nbsp;
<a href="https://arxiv.org/abs/2409.08615"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://lordliang.github.io/DrawingSpinUp/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/LordLiang/DrawingSpinUp"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp; \
*Jie Zhou, Chufeng Xiao, Miu-Ling Lam, Hongbo Fu* \
[13 Sep. 2024] [arXiv, 2024]

**Toon3D: Seeing Cartoons from a New Perspective** &nbsp; | &nbsp;
<a href="https://www.arxiv.org/abs/2405.10320"><img src="./assets/paper.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://toon3d.studio/"><img src="./assets/webpage.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://www.youtube.com/watch?v=tJ7UKALsF-0&feature=youtu.be"><img src="./assets/demo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
<a href="https://github.com/ethanweber/toon3d"><img src="./assets/repo.svg" alt="Icon" width="15" height="15"></a> &nbsp;
[🤗](https://huggingface.co/spaces/ethanweber/toon3d) &nbsp;\
*Ethan Weber, Riley Peterlinz, Rohan Mathur, Frederik Warburg, Alexei A. Efros, Angjoo Kanazawa* \
[2024] [Arxiv, 2024]



## 如何Contribute 
我们鼓励动画爱好者、研究者通过添加相关论文、文章和各类资源的形式为本资料库做出贡献。您的贡献将有助于为任何对动画研究感兴趣的人提供有价值的参考。

只需 fork 本资源库，进行添加或改进，并pull request即可。

---

<div align="center">
    <em>希望动画因我们而更好.</em>
</div>

<div align="center">
   <img src="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/Hatsune_Miku_@illufinch.png" width="40" >
</div>
<p align="center"><sub><i>图标 by Twitter</i>©illufinch</sub></p>
